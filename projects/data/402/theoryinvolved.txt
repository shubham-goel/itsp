<ul><li>Our Approach for voice recognition</li></ul><p><strong>Hidden Markov Model using Cepstral coefficients </strong> : The following steps were followed for voice recognition using Hidden Markov Model Obtaining the signal The first part is obtaining signal from microphone. This is easily achieved by using the audiorecorder object of MATLAB. The getaudiodata function of audiorecorder object gives the signal data in form of column of numbers representing the audio signal. Processing the signal into observation Then comes the feature analysis part of processing.</p><p><strong>Filtering / pre-emphasis</strong><br>First the signal is passed through a part of code which acts as a high pass filter known as fir filter . This spectrally flattens the signal. <br><strong>Voice Activation Detection</strong><br>The signal is now passed to a function which finds the part of signal containing the spoken word and thus returns the signal without silence. Now for the word obtained we proceed further. Now onwards Signal would refer to the extracted words. <br><strong>Finding cepstral coefficients and delta coefficients</strong><br>Using some predefined functions of MATLAB we convert the given signal into a set of observations which can be used for the model. The various operations that are performed are breaking the signal into windows , then applying the window function for each (hamming window is used) , then autocorelation coefficients are obtained, from these coefficients we obtain the cepstral coefficients by levinson durbin algorithm , further these coefficients are weighted to normalize , and the last step involves in finding the delta cepstral coefficients. Thus we get two set of coefficients which are merged to form row of 24 elements for each window and this completes the conversion into observation sequence. <br><strong>Choice of model parameters</strong><br>The number of states we selected was 6 after analysis of number of states versus the error made by the system / model. The data being obtained from paper by Rabiner over speech recognition by HMM model. <br>Next the HMM model to be used is selected to be Left-to-Right as the speech signals have parts which follow one after the other to form a meaningful word. Left-to-Right model has property that the system can move into the same state or a state ahead of it and not backward. The other type being ergodic model where system can move from any state to any other. Training the system/model Training the system here means determining the model parameters so that the given observation sequence used to train the model is declared highly probable by the system and others low. <br><strong>Parameters</strong><br>The parameters for HMM model are transition probabilities between the states represented by matrix A (whose elements at ith row , jth column represent transition probability form ith state to jth), then comes the probabilities of occurrence of each observation in a particular word represented by B_ik meaning probability of kth observation being in ith state , then are the initial probabilities for occurrence of a given state at beginning time. In our case since we have dealt with continuous data the B_ik is represented as a gaussian distribution. <br><strong>Initial e</strong></p>